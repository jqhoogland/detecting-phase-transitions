{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8U839iGXCH3",
        "outputId": "88f12940-8c9e-4cb7-c312-dabd92be351e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (2.0.0)\n",
            "Requirement already satisfied: torchvision in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (0.15.1)\n",
            "Requirement already satisfied: livelossplot in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (0.5.5)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.14.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting torchtyping\n",
            "  Using cached torchtyping-0.1.4-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: filelock in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: numpy in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from torchvision) (1.24.2)\n",
            "Requirement already satisfied: requests in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from torchvision) (2.28.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from torchvision) (9.5.0)\n",
            "Requirement already satisfied: matplotlib in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from livelossplot) (3.7.1)\n",
            "Requirement already satisfied: bokeh in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from livelossplot) (3.1.0)\n",
            "Collecting Click!=8.0.0,>=7.0\n",
            "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Using cached GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from wandb) (5.9.4)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.19.1-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from wandb) (6.0)\n",
            "Collecting pathtools\n",
            "  Using cached pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp311-cp311-macosx_10_9_x86_64.whl (11 kB)\n",
            "Requirement already satisfied: setuptools in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from wandb) (65.6.3)\n",
            "Collecting appdirs>=1.4.3\n",
            "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting protobuf!=4.21.0,<5,>=3.19.0\n",
            "  Downloading protobuf-4.22.3-cp37-abi3-macosx_10_9_universal2.whl (397 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.2/397.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard>=2.11.1\n",
            "  Downloading typeguard-3.0.2-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from requests->torchvision) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: contourpy>=1 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from bokeh->livelossplot) (1.0.7)\n",
            "Requirement already satisfied: packaging>=16.8 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from bokeh->livelossplot) (23.1)\n",
            "Requirement already satisfied: pandas>=1.2 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from bokeh->livelossplot) (2.0.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from bokeh->livelossplot) (6.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from bokeh->livelossplot) (2023.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from matplotlib->livelossplot) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from matplotlib->livelossplot) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from matplotlib->livelossplot) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from matplotlib->livelossplot) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from matplotlib->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from pandas>=1.2->bokeh->livelossplot) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages (from pandas>=1.2->bokeh->livelossplot) (2023.3)\n",
            "Installing collected packages: pathtools, appdirs, typeguard, smmap, setproctitle, sentry-sdk, protobuf, docker-pycreds, Click, gitdb, torchtyping, GitPython, wandb\n",
            "\u001b[33m  DEPRECATION: pathtools is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running setup.py install for pathtools ... \u001b[?25ldone\n",
            "\u001b[?25hSuccessfully installed Click-8.1.3 GitPython-3.1.31 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 protobuf-4.22.3 sentry-sdk-1.19.1 setproctitle-1.3.2 smmap-5.0.0 torchtyping-0.1.4 typeguard-3.0.2 wandb-0.14.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision livelossplot wandb torchtyping tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMX1Jjrj0CzB"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "# Add spectroscope to the path\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k66YJP740uCR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "from livelossplot import PlotLosses\n",
        "import tqdm\n",
        "\n",
        "from spectroscope.data import SubsetsLoader, get_filtered_dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the data\n",
        "mnist_train = MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = MNIST('./data', train=False, download=True, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr0ejX6YM7ej"
      },
      "source": [
        "## Single-layer neural network\n",
        "\n",
        "This an unmodified mnist learner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cTkt86amTqCP"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cpu\") # Uncomment this to run on CPU\n",
        "# DEVICE = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "class MNISTConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1)\n",
        "        self.fc1 = nn.Linear(512, 10)\n",
        "\n",
        "        self.to(DEVICE)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1, 28, 28)\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 512)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkWi8PD9pEGx"
      },
      "source": [
        "# START OF IDEA: Introduction of new digits in training\n",
        "\n",
        "The section aims to see if introducing new digits later in the Epoch gives discontinuous boosts in peformance. I expect it shouldn't, since if we have the model say learn just 0 and 1 in the first half of training, then introduce the number 2, the parameters will be fitted only to (0,1) and do terrible on 2, so I expect a massive dip in accuracy in the middle, then some recovery at the end once it's seen some 0,1,2s but nowhere near the 90%+ as if we just did all 10 from the start. It's highly possible I may have misunderstood the setup, since I don't see how this could give a phase transition in decrease of loss. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkWDKPrZWCOv"
      },
      "source": [
        "The code below is simply testing the filter digit function does as expected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ux2HiG7QPlA",
        "outputId": "45a8af81-62ee-47d5-8781-8802f03a209f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SubsetsLoader((Subset(MNIST, labels=(0,)), Subset(MNIST, labels=(0, 1)), Subset(MNIST, labels=(0, 1, 2)), Subset(MNIST, labels=(0, 1, 2, 3)), Subset(MNIST, labels=(0, 1, 2, 3, 4)), Subset(MNIST, labels=(0, 1, 2, 3, 4, 5)), Subset(MNIST, labels=(0, 1, 2, 3, 4, 5, 6)), Subset(MNIST, labels=(0, 1, 2, 3, 4, 5, 6, 7)), Subset(MNIST, labels=(0, 1, 2, 3, 4, 5, 6, 7, 8)), Subset(MNIST, labels=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))), batch_size=1)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from typing import Any, Tuple, Type\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchtyping import TensorType\n",
        "\n",
        "\n",
        "def as_subset(cls: Type[Dataset]):\n",
        "    \"\"\"\n",
        "    Wrapper for a dataset class that adds a labels attribute to the dataset,\n",
        "    and a __repr__ method that prints the labels.\n",
        "    \"\"\"\n",
        "    class Subset(cls):\n",
        "        def __init__(self, data, targets, train: bool, labels: Tuple[int, ...], **kwargs):\n",
        "            self.labels = labels\n",
        "            self.data = data\n",
        "            self.targets = targets\n",
        "\n",
        "            self.train = train\n",
        "\n",
        "        def __repr__(self):\n",
        "            return f\"Subset({cls.__name__}, labels={self.labels})\"\n",
        "        \n",
        "        def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
        "            \"\"\"\n",
        "            Args:\n",
        "                index (int): Index\n",
        "\n",
        "            Returns:\n",
        "                tuple: (image, target) where target is index of the target class.\n",
        "            \"\"\"\n",
        "            return self.data[index], int(self.targets[index])\n",
        "    \n",
        "    return Subset\n",
        "\n",
        "\n",
        "def filter_by_labels(dataset: Dataset, labels: Tuple[int, ...]):\n",
        "    \"\"\"\n",
        "    Returns an iterator over the dataset, yielding only the images and labels in labels.\n",
        "    \"\"\"\n",
        "    for image, label in dataset:\n",
        "        if label in labels:\n",
        "            yield image, label\n",
        "\n",
        "\n",
        "def get_filtered_dataset(dataset: Dataset, labels: Tuple[int, ...]):\n",
        "    \"\"\"\n",
        "    Returns a new dataset with only the images and labels in labels.\n",
        "    \"\"\"\n",
        "    dataset_cls = as_subset(type(dataset))\n",
        "    data, targets = zip(*((x, y) for x, y in filter_by_labels(dataset, labels)))\n",
        "    return dataset_cls(data, targets, train=dataset.train, labels=labels)  # type: ignore\n",
        "\n",
        "\n",
        "class SubsetsLoader:\n",
        "    \"\"\"\n",
        "    A data loader that trains on different subsets of the dataset \n",
        "    depending on the active subset.\n",
        "\n",
        "    Note: it's up to you to call next_subset() when you want to move to the next subset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        subsets: Tuple[Dataset],\n",
        "        *args,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        self.subsets = subsets\n",
        "        self.subset_idx = 0\n",
        "        self.subloaders = tuple(DataLoader(subset, *args, **kwargs) for subset in subsets)\n",
        "\n",
        "    def next_subset(self):\n",
        "        \"\"\"Moves to the next subset.\"\"\"\n",
        "        if self.subset_idx < len(self.subsets):\n",
        "            self.subset_idx += 1\n",
        "        else:\n",
        "            raise StopIteration\n",
        "         \n",
        "    def to_subset(self, subset_idx: int):\n",
        "        \"\"\"Moves to the subset with index subset_idx.\"\"\"\n",
        "        if subset_idx < len(self.subsets):\n",
        "            self.subset_idx = subset_idx\n",
        "        else:\n",
        "            raise IndexError(f\"Subset index {subset_idx} out of range\")\n",
        "    \n",
        "    @property\n",
        "    def dataset(self):\n",
        "        return self.subsets[self.subset_idx]\n",
        "    \n",
        "    @property\n",
        "    def loader(self):\n",
        "        return self.subloaders[self.subset_idx]\n",
        "    \n",
        "    @property\n",
        "    def batch_size(self):\n",
        "        return self.loader.batch_size\n",
        "\n",
        "    @classmethod\n",
        "    def from_filters(cls, dataset: Dataset, labels_per_subset: Tuple[Tuple[int, ...]]):\n",
        "        \"\"\"\n",
        "        Returns a SubsetsLoader that trains on different subsets of the dataset \n",
        "        depending on the active subset.\n",
        "        \"\"\"\n",
        "        subsets = tuple(get_filtered_dataset(dataset, labels) for labels in labels_per_subset)\n",
        "        return cls(subsets, shuffle=True)\n",
        "        \n",
        "    def __repr__(self):\n",
        "        return f\"SubsetsLoader({self.subsets}, batch_size={self.batch_size})\"\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return iter(self.subloaders[self.subset_idx])\n",
        "\n",
        "subsets_loader = SubsetsLoader.from_filters(\n",
        "    mnist_train,\n",
        "    labels_per_subset=tuple(tuple(range(i+1)) for i in range(0, 10)),\n",
        ")\n",
        "\n",
        "subsets_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "per_label_train_loader = SubsetsLoader.from_filters(\n",
        "    mnist_train,\n",
        "    labels_per_subset=tuple((i,) for i in range(0, 10)),\n",
        ")\n",
        "\n",
        "per_label_test_loader = SubsetsLoader.from_filters(\n",
        "    mnist_test,\n",
        "    labels_per_subset=tuple((i,) for i in range(0, 10)),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Metrics:\n",
        "    def __init__(self, per_label_train_loader, per_label_test_loader, loss_fn):\n",
        "        self.per_label_train_loader = per_label_train_loader\n",
        "        self.per_label_test_loader = per_label_test_loader\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "        self.train_loss = np.zeros(10)\n",
        "        self.train_accuracy = np.zeros(10)\n",
        "        self.test_loss = np.zeros(10)\n",
        "        self.test_accuracy = np.zeros(10)\n",
        "\n",
        "        self.trainset_sizes = np.array([len(subset) for subset in per_label_train_loader.subsets])\n",
        "        self.testset_sizes = np.array([len(subset) for subset in per_label_test_loader.subsets])\n",
        "\n",
        "    def measure(self, model: nn.Module):\n",
        "        with torch.no_grad():\n",
        "            # Loop over each specific-label-restricted subset of data\n",
        "            for l in tqdm(range(10), desc=\"Measuring metrics\"):\n",
        "                self.per_label_train_loader.to_subset(l)\n",
        "                self.per_label_test_loader.to_subset(l)\n",
        "\n",
        "                for i, (x, y) in enumerate(self.per_label_train_loader):\n",
        "                    x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "                    y_pred = model(x)\n",
        "                    _, predicted = torch.max(y_pred.data, 1)\n",
        "                    self.train_accuracy[l] += (predicted == y).sum().item()\n",
        "                    self.train_loss[l] += self.loss_fn(y_pred, y).item()\n",
        "\n",
        "                self.train_accuracy[l] /= self.trainset_sizes[l]\n",
        "                self.train_loss[l] /= self.trainset_sizes[l]\n",
        "\n",
        "                for i, (x, y) in enumerate(self.per_label_test_loader):\n",
        "                    x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "                    y_pred = model(x)\n",
        "                    _, predicted = torch.max(y_pred.data, 1)\n",
        "                    self.test_accuracy[l] += (predicted == y).sum().item()\n",
        "                    self.test_loss[l] += self.loss_fn(y_pred, y).item()\n",
        "\n",
        "                self.test_accuracy[l] /= self.testset_sizes[l]\n",
        "                self.test_loss[l] /= self.testset_sizes[l]\n",
        "\n",
        "    def reset(self):\n",
        "        self.train_loss = np.zeros(10)\n",
        "        self.train_accuracy = np.zeros(10)\n",
        "        self.test_loss = np.zeros(10)\n",
        "        self.test_accuracy = np.zeros(10)\n",
        "\n",
        "    @property\n",
        "    def total_train_size(self):\n",
        "        return self.trainset_sizes.sum() \n",
        "    \n",
        "    @property\n",
        "    def total_test_size(self):\n",
        "        return self.testset_sizes.sum()\n",
        "\n",
        "    @property\n",
        "    def total_train_loss(self):\n",
        "        return (self.train_loss * self.trainset_sizes).sum() / self.total_train_size\n",
        "    \n",
        "    @property\n",
        "    def total_test_loss(self):\n",
        "        return (self.test_loss * self.testset_sizes).sum() / self.total_test_size\n",
        "\n",
        "    @property\n",
        "    def total_train_accuracy(self):\n",
        "        return (self.train_accuracy * self.trainset_sizes).sum() / self.total_train_size\n",
        "    \n",
        "    @property\n",
        "    def total_test_accuracy(self):\n",
        "        return (self.test_accuracy * self.testset_sizes).sum() / self.total_test_size\n",
        "\n",
        "    def as_dict(self):\n",
        "        d = {\n",
        "            \"train/loss/total\": self.total_train_loss,\n",
        "            \"test/loss/total\": self.total_test_loss,\n",
        "            \"train/accuracy/total\": self.total_train_accuracy,\n",
        "            \"test/accuracy/total\": self.total_test_accuracy,\n",
        "        }\n",
        "\n",
        "        for l in range(10):\n",
        "            d[f\"train/loss/{l}\"] = self.train_loss[l]\n",
        "            d[f\"test/loss/{l}\"] = self.test_loss[l]\n",
        "            d[f\"train/accuracy/{l}\"] = self.train_accuracy[l]\n",
        "            d[f\"test/accuracy/{l}\"] = self.test_accuracy[l]\n",
        "\n",
        "        return d      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIEtfSdVWM1P"
      },
      "source": [
        "Now we check whether we still get good accuracy with only 0, 1 and 2 in the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCRR4gtvxzCe"
      },
      "source": [
        "So as we can see we still get good accuracy with less digits, althought there appears to be much more variation in the accuracy which was not expected, and that it takes longer to get to a good accuracy which doesnt make much sense to me. Now we will try to train this model to learn on 0s and 1s only, then we introduce 2 halfway into the second half of training (Epoch 50) to see if there is discontinuity in performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "id": "bEYUIhm5x-r5",
        "outputId": "d7bd74dd-db69-45be-e9d8-6f20ad5a5e33"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/Jesse/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:xz6mrqhr) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">amber-wildflower-4</strong> at: <a href='https://wandb.ai/jqhoogland/detecting-phase-transitions-sandbox/runs/xz6mrqhr' target=\"_blank\">https://wandb.ai/jqhoogland/detecting-phase-transitions-sandbox/runs/xz6mrqhr</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230415_140353-xz6mrqhr/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:xz6mrqhr). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/Jesse/Projects/detecting-phase-transitions/sandbox/wandb/run-20230415_141607-zu4fqy8c</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jqhoogland/detecting-phase-transitions-sandbox/runs/zu4fqy8c' target=\"_blank\">ruby-wood-5</a></strong> to <a href='https://wandb.ai/jqhoogland/detecting-phase-transitions-sandbox' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/jqhoogland/detecting-phase-transitions-sandbox' target=\"_blank\">https://wandb.ai/jqhoogland/detecting-phase-transitions-sandbox</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/jqhoogland/detecting-phase-transitions-sandbox/runs/zu4fqy8c' target=\"_blank\">https://wandb.ai/jqhoogland/detecting-phase-transitions-sandbox/runs/zu4fqy8c</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Next subset: Subset(MNIST, labels=(0, 1))\n",
            "Next subset: Subset(MNIST, labels=(0, 1, 2))\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[43], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[1;32m     43\u001b[0m metrics \u001b[39m=\u001b[39m Metrics(per_label_train_loader, per_label_test_loader, loss_fn)\n\u001b[0;32m---> 45\u001b[0m train(model, loss_fn, optimizer, subsets_loader, metrics)\n",
            "Cell \u001b[0;32mIn[43], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, optimizer, subsets_loader, metrics)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     19\u001b[0m     metrics\u001b[39m.\u001b[39mreset()\n\u001b[0;32m---> 20\u001b[0m     metrics\u001b[39m.\u001b[39;49mmeasure(model)\n\u001b[1;32m     21\u001b[0m     wandb\u001b[39m.\u001b[39mlog(metrics\u001b[39m.\u001b[39mas_dict(), step\u001b[39m=\u001b[39mstep)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Make predictions with the current parameters.\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[42], line 24\u001b[0m, in \u001b[0;36mMetrics.measure\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m i, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(per_label_train_loader):\n\u001b[1;32m     23\u001b[0m     x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(DEVICE), y\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 24\u001b[0m     y_pred \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     25\u001b[0m     _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(y_pred\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n\u001b[1;32m     26\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_accuracy[l] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (predicted \u001b[39m==\u001b[39m y)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n",
            "File \u001b[0;32m~/Projects/detecting-phase-transitions/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[4], line 19\u001b[0m, in \u001b[0;36mMNISTConvNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x))\n\u001b[1;32m     18\u001b[0m x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mmax_pool2d(x, \u001b[39m2\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m512\u001b[39;49m)\n\u001b[1;32m     20\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x)\n\u001b[1;32m     21\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "def train(model: nn.Module, loss_fn, optimizer, subsets_loader: SubsetsLoader, metrics: Metrics):\n",
        "    wandb.init(\"detecting-phase-transitions\")\n",
        "\n",
        "    step = 0\n",
        "    \n",
        "    # Epochs change in size, so we want to keep the number of steps constant between changes\n",
        "    while step < 10_000: \n",
        "        train_loss = 0.\n",
        "\n",
        "        # Training loop for mini-batches\n",
        "        for x, y in subsets_loader:\n",
        "            if step % 1000 == 0 and step > 0:\n",
        "                subsets_loader.next_subset()\n",
        "                print(\"Next subset:\", subsets_loader.dataset)\n",
        "            \n",
        "            if step % 100 == 0:\n",
        "                metrics.reset()\n",
        "                metrics.measure(model)\n",
        "                wandb.log(metrics.as_dict(), step=step)\n",
        "            \n",
        "            # Make predictions with the current parameters.\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            y_pred = model(x)\n",
        "\n",
        "            # Compute the loss value.\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Update the parameters.\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            step += 1\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "model = MNISTConvNet()\n",
        "loss_fn = nn.CrossEntropyLoss(size_average=False)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "metrics = Metrics(per_label_train_loader, per_label_test_loader, loss_fn)\n",
        "\n",
        "train(model, loss_fn, optimizer, subsets_loader, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
